# Contents #

This page explains how to add a new backend to Neco. This includes:
  * [where to start](#Setup_the_project_tree.md)
  * [how perform command line integration](#Update_command_line_interface.md)
  * [extend the compiler](#Extend_the_compiler.md)
    * [write the compilation callbacks](#Compilation_callbacks.md)
    * [write the marking metatype](#Define_the_marking_metatype.md)
    * [define target language grammar](#Target_language_grammar.md)
    * [transform Neco intermediate representation to target language AST](#NecoIR_to_target_language_AST.md)
    * [write target language unparser](#Target_language_unparser.md)
  * [update installation chain](#Update_the_installation_chain.md)

# Setup the project tree #

The first step is to checkout branch `backend-stub`. This branch provides basic integration for a new backend called `stub`. The rest of this document assumes you are working on this branch.

This page differs from the `master` branch by providing modification in files:
  * `setup.py` (installation chain integration)
  * `compilecli.py` (command line integration)
  * `nedo/backend/__init__.py` (expose the new backend)
and provides new files:
  * `neco/asdl/stub.asdl` (target language grammar)
  * `nedo/backends/stub/__init__.py` (expose the backend)
  * `nedo/backends/stub/compile_impl.py` (compilation callbacks)
  * `nedo/backends/stub/netir.py` (AST transformation)
  * `nedo/backends/stub/nettypes.py` (Markings metatype definition)
  * `nedo/backends/stub/priv/__init__.py` (expose Marking metatype helpers)
  * `nedo/backends/stub/priv/placetypes.py` (Marking metatype helpers)
  * `nedo/backends/stub/unparse.py` (target language unparser)

# Update command line interface #

Integration in the command line is straight forward. It only consists in adding a new value for language selection.
```
parser.add_argument('--lang', '-l', default = 'python', dest = 'language', 
                    choices = ['python', 'cython', 'stub'],
                    help = 'set target language')
```
We just added `stub` language to `choices`.

If you want to update the cleanup step you can also update `g_produced_files` variable which holds names of generate files
```
g_produced_files = [..., "net.stub"]
```
Now the neco cleanup operation will also remove `net.stub` files.


---

_You will be able to use tour backend by calling `neco-compile -l stub <other options>`_ (available after [updating the compilation chain](#Update_the_installation_chain.md))

---


# Extend the compiler #

Extending the compiler is the most time consuming step.

## Compilation callbacks ##

The compilation callbacks is the entry point of the backend. It is defined in file `nedo/backends/stub/compile_impl.py` and is composed of three functions:
  * `new_marking_type` which returns a new marking metatype, this function simply creates a new `MarkingType` object.
```
  def new_marking_type(name, config):
      return nettypes.MarkingType(config)
```

  * `new_compiling_environment` which returns a new compiling environment, this is also a simple constructor call.
```
  def new_compiling_environment(config, net_info, word_set, marking_type):
      return Env(config, net_info, word_set, marking_type)
```


  * `compile_IR` which is called to compile the Neco intermediate representation, this is the most complicated callback and the rest of this section will explain how it works.

The prelude of the `compile_IR` callback is dedicated to handle compilation options like additional imports of files or generating code used for global variables.
```
def compile_IR(env, config, compiler_):
    search_paths = config.search_paths

    for mod in config.imports:
        # handle additional imports        
        pass

    for name, value  in compiler_.net.globals:
        # handle globals
        pass
```

Then addresses the compilation of the Neco intermediate representation.
```
    compiled_nodes = [] # list of top level AST nodes
```

The backend decides how markings are represented, Neco helps to optimize the representation by providing information about places but the backend decides how it is represented in target language. So we generate an API to handle the marking type, this is done using a marking metatype stored in `env.marking_type`. How to define the marking metatype is explained in [next section](#Define_the_marking_metatype.md). When this step is done, the `try`-`catch` should be removed.
```
    try:
        # generate marking type API
        compiled_nodes.append( env.marking_type.generate_api(env) )
    except NotImplementedError:
        print "marking_type.generate_api not implemented"
```

The next step is to compile each of exploration functions generated by Neco. This is done using a transformation implemented in `netir.CompilerVisitor`. Because we do not have a fully implemented transformation it raises a `NotImplementedError` then we provide a fallback AST for test purposes (that will be used in next compilation phase).
```
    try:
        # transform Neco intermediate representation
        compiler = netir.CompilerVisitor(env, config)
        
        for node in env.function_nodes():
            compiled_nodes.append(compiler.compile(node))

    except NotImplementedError:
        print "netir.CompilerVisitor not implemented"
        compiled_nodes.append(stub_ast.Stub([stub_ast.StubDef("test",
                                                              [ stub_ast.StubEntry(["e1", "e2"]),
                                                                stub_ast.StubEntry(["e3", "e4"])]
                                                              )
                                             ]))
```

Now we have our compiled code in target language AST, so we need to produce a file and print it, this is the goal of the `unparser` of our language.
```
    module_name = config.out_module
    f = open(module_name + '.stub', "w")

    # write file
    Unparser(compiled_nodes, f)

    f.write('\n')
    return None
```
The return value is used in python and cython backend to return the compiled python module, this way it can be used on the fly. Non pythonic languages will not use this return value.

## Define the marking metatype ##

The exploration engine produced by Neco il a set of transformer functions that produce markings. These markings are specialized for each model. The marking metatype is used to define how this marking is implemented.

The usual approach in Neco is to define a marking metatype that stores place metatypes which handle each place independently. For example, in Cython backend, the marking metatype defines a class and how attributes are stored then place metatypes define how to use these attributes. In Cython case different places may use the same attribute to encode compressed data.

### Marking metatype ###

The stub marking metatype is defined in `nedo/backends/stub/nettypes.py`. This contains a class `MarkingType` that extends `neco.core.nettypes.MarkingType`. This class has two important functions:
  * `gen_types` which is called by Neco to create place types;
  * `gen_api` which is called by the compilation callback to produce marking API code.

`gen_types` consists in two for loops that iterate over places and create place types. Assuming that there is a `priv.placetypes.ObjectPlaceType` this could be implemented as:
```
    def gen_types(self):
        for place_info in self.one_safe_places:
            place_type = priv.placetypes.ObjectPlaceType(place_info, marking_type=self)
            self.place_types[place_name] = place_type

        for place_info in self.places:
            place_name = place_info.name
            place_type = priv.placetypes.ObjectPlaceType(place_info, marking_type=self)
            self.place_types[place_name] = place_type
```
Each instance of `place_info` stores data about the place for example you could use another place metatype based on place type in the Perti net.
```
if place_info.type.is_BlackToken:                
    place_type = priv.placetypes.BTPlaceType(place_info, marking_type=self)
```
For more info about `PlaceInfo` refer to `neco.core.info`.

### Place metatypes ###

Each place is implemented by a place metatype these are by convention written in `priv.placetypes`. These extend from `neco.core.nettypes.PlaceType` and provide some common traits that are used by neco. The remaining methods are implementation specific.

The stub provides common methods that are when building target language AST.

## Target language grammar ##

To build an AST for your target language you first need to define a grammar. This is done using SNAKES ASDL files located in `neco/asdl`.

The stub provides a minimalistic one
```
module stub version "0.1"
{
	Stub = (Stmt* body)
	
	Stmt = StubDef(identifier name, Stmt* body)
	     | StubEntry(identifier* names)
}
```

The first line gives the grammar a name and a version number. Then the body define grammar rules.

Each non terminal or terminal (`Stub`, Stmt`,`StubDef` `StubEntry`) will produce a class of the same name:
  * `Stub` class will have an attribute body which is a list of `Stmt` objects;
  * `StubDef` and `StubEntry` will have `Stmt` as a base class,
  * `StubDef` will have attributes `name` of type string and `body` which is a list of `Stmt`,
  * `StubEntry` will only have an attribute `names` which is a list of strings.

Moreover, each class is augmented with predicate functions: `isStub`, `isStmt`, `isStubDef`, `isStubEnrty`.

The is generated in `neco/asdl/stub.py` and is easily readable. Then it can be used to build an AST:
```
Stub([ StubDef("test", 
               [ StubEntry(["e1", "e2"]), 
                 StubEntry(["e3", "e4"])])
     ])
```

Refer to `neco/asdl/netir.asdl` for Neco intermediate representation grammar.


---

_An useful tip is to use `python setup.py dev` to regenerate ASTs (this is available after [updating the installation chain](#Update_the_installation_chain.md))_

---


## NecoIR to target language AST ##

The code generation is mainly based on AST transformation. We transform NecoIR (`neco/asdl/netir.asdl`) to target language. This is done by matching each AST node and producing new node or a list of nodes.

This is done with a visitor pattern implemented in `neco.backends.netir.CompilerVisitor` that dispatch each node to adequate methods. The entry point is `CompilerVisitor.compile` function. Then each rule is handled by a `compile_{AST_NODE}` method. For example NecoIR `If` node is handled by `compile_If` method.

In Python backend the If rule is straight forward to implement:
```
    def compile_If(self, node):
        return pyast.If(test   = self.compile(node.condition),
                        body   = self.compile(node.body),
                        orelse = self.compile(node.orelse))
```
The AST If node to compile is `node`, we translate it to python `pyast.If` node and compile all sub-nodes (`condition`, `body`, `orelse`) by calling `self.compile` this will delegate the transformation to adequate methods.

This step is time consuming but most of it is straight forward, refer to python backend (`neco.backends.python.netir`) for an example.

## Target language unparser ##

Our AST generated we need to print it to a file, this is the role of an unparser. A simple unparser for the Stub language is written in `neco.backends.stub.unparser`. As for AST transformations, the unparser uses a visitor pattern. The entry point is `unparse` function which creates an unparser and runs the unparsing chain. The unparser dispatches each AST rule to a `_{AST_NODE}` method for example `StubEntry` node is delegated to `_StubEntry`.

```
class Unparser:
    
    def __init__(self, tree, out_file = sys.stdout):
       ...

    def dispatch(self, tree):
       ...

    def write(self, text):
       ...

    def enter(self):
       ...

    def leave(self):
       ...

    def fill(self, text = ""):
       ...
```

The base implementation provides an constructor, and the entry point dispatch method that calls adequate methods. Then we have four helper methods:
  * `write` that writes text to a stream;
  * `enter`, `leave` and `fill` for scope based indentation, `enter` increments indentation level, `leave` decrements it, and `fill` writes white spaces for indentation then some text.

Then we just write printers for each rule using these methods:
```
    def _str(self, s):
        self.write(s)

    def _Stub(self, tree):
        for stmt in tree.body:
            self.dispatch(stmt)

    def _StubDef(self, tree):
        self.fill("StubDef " + tree.name + " => ")
        self.enter()
        self.dispatch(tree.body)
        self.leave()
        self.write("\n")

    def _StubEntry(self, tree):
        self.fill("entry ")
        interleave(lambda: self.write(", "), self.dispatch, tree.names)
```

Running the unparser is simple
```
ast = Stub([ StubDef("test", 
               [ StubEntry(["e1", "e2"]), 
                 StubEntry(["e3", "e4"])])
     ])
unparse(ast)
```
will print
```
StubDef test => 
    entry e1, e2
    entry e3, e4
```

# Update the installation chain #

The last step is to update the installation chain which is defined in `setup.py`.
  * add ASDL generation
```
def gen_asdl():
    ...
    compile_asdl('neco/asdl/stub.asdl',         'neco/asdl/stub.py')
```
  * add neco packages to install
```
setup(...
      packages=[...
                'neco.backends.stub',
                'neco.backends.stub.priv',],
      ...)
```
> You may also update `package_data` here if your backend needs to install some non python files. For example, Cython backend install template files that are used as preludes during code generation.


---

_After this step installation is performed in the usual way `python setup.py <options>`_

---
